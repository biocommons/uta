#!/usr/bin/env python

"""Write exonsets and txinfo files from NCBI GFF alignments, as obtained from
ftp://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/alignments/
This service appeared in April 2015 and is due to update weekly.

See uta.formats for a description of those file formats.

In a nutshell, this means that you'll get data like this:

ncbi.txinfo.gz:
origin  ac  hgnc    cds_se_i    exons_se_i
NCBI RefSeq NM_053283.2 DCD 62,395  0,120;120,159;159,261;261,351;351,517

ncbi.exonsets.gz:
tx_ac   alt_ac  method  strand  exons_se_i
NM_130786.3 NC_000019.9 splign  -1  58864769,58864865;588646...
NM_130786.3 NC_018930.2 splign  -1  58858699,58858795;588585...
NM_130786.3 AC_000151.1 splign  -1  55173924,55174020;551738...
NM_138933.2 NC_000010.10    splign  -1  52645340,52645435;52...

UTA requires that the exon structure of a transcript accession as
defined on its own sequence is unique. Although this is mostly true,
there are instances where NCBI reports different exon structures for a
single transcript. For example, NM_001300954.1 aligns with 11 exons on
NC_000011.9 and 5 exons on NW_003871081.1, and the differences are NOT
due merely to concatenation of adjacent spans.  This script warns
vaguely about this problem 

"""


from __future__ import division

import argparse
import collections
import gzip
import io
import itertools
import logging
import logging.config
import os
import pprint
import pkg_resources
import re
import sys

import attr
import prettytable

import Bio.SeqIO
from bioutils.digests import seq_md5

from uta.formats.exonset import ExonSet, ExonSetWriter
from uta.formats.txinfo import TxInfo, TxInfoWriter, TxInfoReader
from uta.formats.geneaccessions import GeneAccessionsReader

origin = "NCBI"


@attr.s(slots=True)
class ExonAlignment(object):
    """alignment of a single exon"""
    ref_ac = attr.ib()
    origin = attr.ib()
    match_type = attr.ib()
    g_start = attr.ib(converter=int)
    g_end = attr.ib(converter=int)
    score = attr.ib(converter=float)
    strand = attr.ib()
    aln_id = attr.ib()
    tx_ac = attr.ib()
    tx_start = attr.ib(converter=int)
    tx_end = attr.ib(converter=int)
    pct_coverage = attr.ib(converter=float)
    pct_identity_gap = attr.ib(converter=float)
    pct_identity_ungap = attr.ib(converter=float)


@attr.s(slots=True)
class TranscriptAlignment(object):
    """Represents a set of ExonAlignments for a single alignment id in tx exon start order"""

    exon_alignments = attr.ib()

    def __getitem__(self, sl):
        return self.exon_alignments.__getitem__(sl)

    def __len__(self):
        return len(self.exon_alignments)

    @property
    def tx_exons_se_i(self):
        return ";".join("{s},{e}".format(s=ea.tx_start-1, e=ea.tx_end) for ea in self.exon_alignments)

    @property
    def ref_exons_se_i(self):
        return ";".join("{s},{e}".format(s=ea.g_start-1, e=ea.g_end) for ea in self.exon_alignments)

    @property
    def tx_lens(self):
        return [(ea.tx_end-ea.tx_start+1) for ea in self.exon_alignments]

    @property
    def ref_lens(self):
        return [(ea.g_end-ea.g_start+1) for ea in self.exon_alignments]

    @property
    def ref_ac(self):
        return self.exon_alignments[0].ref_ac

    @property
    def origin(self):
        return self.exon_alignments[0].origin

    @property
    def score(self):
        return self.exon_alignments[0].score

    @property
    def strand(self):
        return self.exon_alignments[0].strand

    @property
    def aln_id(self):
        return self.exon_alignments[0].aln_id

    @property
    def tx_ac(self):
        return self.exon_alignments[0].tx_ac

    @property
    def pct_coverage(self):
        return self.exon_alignments[0].pct_coverage

    @property
    def pct_identity_gap(self):
        return self.exon_alignments[0].pct_identity_gap

    @property
    def pct_identity_ungap(self):
        return self.exon_alignments[0].pct_identity_ungap


def parse_args(argv):
    ap = argparse.ArgumentParser(
        description=__doc__,
    )
    ap.add_argument("in_fn")
    ap.add_argument("--origin", "-o",
                    default=origin)
    ap.add_argument("--prefix", "-p",
                    default="ncbi-gff")
    ap.add_argument("--geneacs", "-G")
    ap.add_argument("--txinfo", "-T", required=False)
    ap.add_argument("--strict-coverage",         "-C", type=float, default=95.0)
    ap.add_argument("--min-coverage",            "-c", type=float, default=85.0)
    ap.add_argument("--strict-pct-identity-gap", "-I", type=float, default=95.0)
    ap.add_argument("--min-pct-identity-gap",    "-i", type=float, default=85.0)

    opts = ap.parse_args(argv)

    assert opts.strict_coverage > opts.min_coverage
    assert opts.strict_pct_identity_gap > opts.min_pct_identity_gap

    return opts


def read_exon_alignments(fn):
    """read lines of NCBI's alignment gff file, fn, returning ExonAlignment records"""

    # NC_000007.13	RefSeq	cDNA_match	50344265	50344518	254	+	.	ID=aln58042;Target=NM_001220765.2 1 254 +;gap_count=0;identity=0.0691326;idty=1;num_ident=428;num_mismatch=0;pct_coverage=6.91326;pct_identity_gap=100;pct_identity_ungap=100;score=254
    # NC_000002.11  RefSeq  cDNA_match  179671939   179672150             212 -   .               ID=ed951d46-194c-477a-a480-4bc64530c5ba;Target=NM_001267550.2 1 212 +;gap_count=0;identity=0.999991;idty=1;num_ident=109223;num_mismatch=1;pct_coverage=100;pct_identity_gap=99.9991;pct_identity_ungap=99.9991
    line_re = re.compile(
        "(?P<ref_ac>\S+)\s+(?P<origin>\S+)\s+(?P<match_type>\S+)\s+"
        "(?P<g_start>\d+)\s+(?P<g_end>\d+)\s+(?P<score>\S+)\s+"
        "(?P<strand>[-+])\s+\.\s+ID=(?P<aln_id>[^;]+);Target=(?P<tx_ac>\S+)"
        "\s+(?P<tx_start>\d+)\s+(?P<tx_end>\d+).+?"
        "pct_coverage=(?P<pct_coverage>[^;]+);"
        "pct_identity_gap=(?P<pct_identity_gap>[^;]+);"
        "pct_identity_ungap=(?P<pct_identity_ungap>[^;]+)"
    )
    fh = io.open(fn, "rt")
    for line in fh.readlines():
        if not line.startswith('#'):
            try:
                yield ExonAlignment(**line_re.match(line).groupdict())
            except AttributeError:
                raise Exception("Failed at", line)


def read_transcript_alignments(fn):
    """read an NCBI alignment gff, returning a generator of TranscriptAlignments
    that contains alignments grouped on id and sorted by tx_start

    This code assumes that alignments with the same alignment id occur
    in contiguous blocks in the file.

    """

    exon_alignments = read_exon_alignments(fn)
    return [TranscriptAlignment(exon_alignments=sorted(exons_i, key=lambda e: e.tx_start))
            for _, exons_i in itertools.groupby(exon_alignments, key=lambda e: e.aln_id)]


def group_transcript_alignments(transcript_alignments):
    """group transcript_alignments by tx_ac and ref_ac

    IMPORTANT: The gff file may contain multiple alignments for a
    <tx_ac, ref_ac> pair.  These pairs are not necessarily adjacent in
    the file. Therefore, the source must be materialized in order to
    sort and group transcript_alignments.

    """

    def _key(e):
        return (e.tx_ac, e.ref_ac)
    transcript_alignments = list(transcript_alignments)
    transcript_alignments.sort(key=_key)
    return ((key, list(alns_i))
            for key, alns_i in itertools.groupby(transcript_alignments, key=_key))


def convert_exon_data(opts, transcript_alignment):
    """return (TxInfo,ExonSet) tuple for given exon record data"""
    ti = TxInfo(ac=transcript_alignment.tx_ac,
                origin=opts.origin,
                hgnc=None,
                cds_se_i=None,
                exons_se_i=transcript_alignment.tx_exons_se_i
                )
    es = ExonSet(
        tx_ac=transcript_alignment.tx_ac,
        alt_ac=transcript_alignment.ref_ac,
        method="splign",
        strand=-1 if transcript_alignment.strand == "-" else 1,
        exons_se_i=transcript_alignment.ref_exons_se_i
    )
    return (ti, es)


if __name__ == "__main__":
    logging_conf_fn = pkg_resources.resource_filename(
        "uta", "etc/logging.conf")
    logging.config.fileConfig(logging_conf_fn)
    logging.getLogger().setLevel(logging.INFO)
    logger = logging.getLogger(__name__)

    opts = parse_args(sys.argv[1:])

    if opts.geneacs:
        gar = GeneAccessionsReader(gzip.open(opts.geneacs, "rt"))
        tx2gene = {ga.tx_ac: ga.hgnc for ga in gar}
        logger.info(
            "read {} gene-accession mappings from {}".format(len(tx2gene), opts.geneacs))
    else:
        tx2gene = None
        logger.info("No geneacs (-G) file provided; gene info will be empty.")
        
    if opts.txinfo:
        tir = TxInfoReader(gzip.open(opts.txinfo, "rt"))
        tx2ti = {ti.ac: ti for ti in tir}
        logger.info(
            "read {} CDS data from {}".format(len(tx2ti), opts.txinfo))
    else:
        tx2ti = None
        logger.info("No gbff txinfo provided (-T); CDS start,end will be undefined for all transcripts and transcript-genome exon structures will not be verified")

    es_fn = opts.prefix + "exonset.gz"
    ti_fn = opts.prefix + "txinfo.gz"

    esw = ExonSetWriter(gzip.open(es_fn + ".tmp", "wt"))
    tiw = TxInfoWriter(gzip.open(ti_fn + ".tmp", "wt"))

    ties = {}
    ti_written = collections.defaultdict(lambda: False)
    ac_not_in_gbff = set()
    ac_exons_differ = set()
    ac_in_source = set()
    ac_failed = set()

    bins = "nogbff esdiffer unique multiple minimum none".split()
    sets = collections.defaultdict(lambda: {k: list() for k in bins})

    transcript_alignments = read_transcript_alignments(opts.in_fn)
    logger.info(
        "read {} transcript alignments from {}".format(len(transcript_alignments), opts.in_fn))

    for _, txalns in group_transcript_alignments(transcript_alignments):
        assert len(txalns) > 0

        ta0 = txalns[0]
        tx_ac, ref_ac = ta0.tx_ac, ta0.ref_ac
        skey = "{:.2s} {:.2s}".format(tx_ac, ref_ac)
        bin = None
        
        # ############################################################
        # Optionally compare exon structure from gbff with input gff
        # And get cds s,e from gbff (sigh)
        if tx2ti is None:
            cds_se_i = None
            txalns_esm = txalns
        else:
            if tx_ac not in tx2ti:
                logger.warn("{ta.tx_ac}~{ta.ref_ac}: no transcript info in {opts.txinfo}; skipping transcript".format(
                    ta=ta0, opts=opts))
                ac_not_in_gbff.add(tx_ac)
                bin = "nogbff"
                sets[skey][bin] += [txalns]
                continue

            gbff_ti = tx2ti[tx_ac]
            txalns_esm = [ta for ta in txalns if ta.tx_exons_se_i == gbff_ti.exons_se_i]
            n_rm = len(txalns) - len(txalns_esm)
            if n_rm > 0:
                logger.warn("{ta.tx_ac}~{ta.ref_ac}: Removed {n_rm}/{n_tot} exon structures that differ from gbff definition".format(
                    n_rm=n_rm, n_tot=len(txalns), ta=ta, opts=opts))
            if len(txalns_esm) == 0:
                logger.warn("{ta.tx_ac}~{ta.ref_ac}: All {n} exon structures differ from gbff definition; skipping alignment".format(
                    ta=ta, opts=opts, n=len(txalns)))
                ac_exons_differ.add(tx_ac)
                bin = "esdiffer"
                sets[skey][bin] += [txalns]
                continue

            cds_se_i = gbff_ti.cds_se_i  # possibly None

        
        # ############################################################
        # Filter alignments by coverage and pct_identity_gap
        # From Terence Murphy, NCBI:
        # "For remapping variation, we typically only use transcript
        # and RefSeqGene alignments that meet the filter:
        # 'pct_identity_gap >= 99.5 and pct_coverage >= 95'"
        txalns_strict = [txaln
                         for txaln in txalns_esm
                         if (txaln.pct_coverage > opts.strict_coverage
                             and txaln.pct_identity_gap > opts.strict_pct_identity_gap)]

        if len(txalns_strict) == 1:

            txalns_load = txalns_strict
            bin = "unique"

        elif len(txalns_strict) > 1:

            logger.warn("{ta.tx_ac}~{ta.ref_ac}: Multiple ({n}) strict alignments; cov/pig: {stats}".format(
                ta=txalns_strict[0], n=len(txalns_strict), opts=opts,
                stats = "; ".join("{ta.pct_coverage}/{ta.pct_identity_gap}".format(ta=ta) for ta in txalns_strict),
                ))
            txalns_load = txalns_strict
            bin = "multiple"

        if len(txalns_strict) == 0:

            txalns_min = [txaln
                          for txaln in txalns_esm
                          if (txaln.pct_coverage > opts.min_coverage
                              and txaln.pct_identity_gap > opts.min_pct_identity_gap)]
            if len(txalns_min) == 0:
                logger.warn("{ta.tx_ac}~{ta.ref_ac}: No usable alignments; cov/pig: {stats}".format(
                    ta=txalns[0],
                    stats = "; ".join("{ta.pct_coverage}/{ta.pct_identity_gap}".format(ta=ta) for ta in txalns_esm),
                    ))
                bin = "none"
            else:
                logger.warn("{ta.tx_ac}~{ta.ref_ac}: Resorting to minimum criteria; loading {n} alignments; cov/pig: {stats}".format(
                    ta=txalns_min[0], n=len(txalns_min),
                    stats = "; ".join("{ta.pct_coverage}/{ta.pct_identity_gap}".format(ta=ta) for ta in txalns_min),
                    ))
                bin = "minimum"
            txalns_load = txalns_min

        sets[skey][bin] += [txalns_esm]

        for ta in txalns_load:
            ti, es = convert_exon_data(opts, ta)
            ti.cds_se_i = cds_se_i
            ac_in_source.add(tx_ac)
            ti.hgnc = tx2gene.get(ti.ac, None)

            if not ti_written[ti.ac]:
                # write a single txinfo line once; multiple may occur for multiple alignments of e.g., one NM to NC, NW, NT
                tiw.write(ti)
                ti_written[ti] = True

            esw.write(es)

    # END HEINOUS LOOP

    for fn in [ti_fn, es_fn]:
        os.rename(fn + ".tmp", fn)

    seen_but_failed = ac_failed - ac_in_source
    if seen_but_failed:
        logger.warn("{n_acv} acvs seen but failed criteria: {acs}".format(
            n_acv=len(seen_but_failed), acs=",".join(sorted(seen_but_failed))))

    if ac_not_in_gbff:
        s_not_g_b = set(k.partition(".")[
                        0] for k in ac_in_source) - set(k.partition(".")[0] for k in tx2gene.keys())
        logger.warn("{n_acv} acvs ({n_ac} base acs) in source not in geneacs file: {acs}".format(
            n_acv=len(ac_not_in_gbff), n_ac=len(s_not_g_b), opts=opts, acs=",".join(sorted(ac_not_in_gbff))))

    if ac_exons_differ:
        logger.warn("{n} accessions in gbff-derived txinfo have different exon coordinates: {acs}".format(
            n=len(ac_exons_differ), opts=opts, acs=",".join(sorted(ac_exons_differ))))

    pprint.pprint(opts)
    pt = prettytable.PrettyTable(field_names=["ac_pair"]
                                 + bins
                                 + "max_coverage max_pct_identity_gap nobgffs nogbff_noup esdiffers nones".split()
                                 )
    for ack in sorted(sets.keys()):
        n = 5
        nogbff_acs = sorted(set(ta.tx_ac for ta in itertools.chain.from_iterable(sets[ack]["nogbff"])))[:n]
        esdiffer_acs = sorted(set(ta.tx_ac for ta in itertools.chain.from_iterable(sets[ack]["esdiffer"])))[:n]
        nones = list(itertools.chain.from_iterable(sets[ack]["none"]))
        nones_acs = sorted(set(ta.tx_ac for ta in nones))[:n]
        max_pct_identity_gap = "{:.2f}".format(max(ta.pct_identity_gap for ta in nones)) if nones else "n/a"
        max_pct_coverage = "{:.2f}".format(max(ta.pct_coverage for ta in nones)) if nones else "n/a"

        nogbff_noup = sorted(
            set(ta.tx_ac.split('.')[0] for ta in itertools.chain.from_iterable(sets[ack]["nogbff"]))
            - set(ta.tx_ac.split('.')[0] for ta in itertools.chain.from_iterable(sets[ack]["unique"]))
            - set(ta.tx_ac.split('.')[0] for ta in itertools.chain.from_iterable(sets[ack]["multiple"]))
            )

        pt.add_row([ack] + [len(sets[ack][bk]) for bk in bins] +
                   [max_pct_coverage, max_pct_identity_gap,
                    " ".join(nogbff_acs),
                    str(len(nogbff_noup)) + ": " + " ".join(nogbff_noup[:n]),
                    " ".join(esdiffer_acs),
                    " ".join(nones_acs) ])
    print(pt)
