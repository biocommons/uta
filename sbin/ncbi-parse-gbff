#!/usr/bin/env python

"""Write exonsets and txinfo files from NCBI GFF alignments, as obtained from
ftp://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/alignments/
This service appeared in April 2015 and is due to update weekly.

See uta.formats for a description of those file formats.

In a nutshell, this means that you'll get data like this:

ncbi.txinfo.gz:
origin  ac  gene_id gene_symbol    cds_se_i    exons_se_i
NCBI RefSeq NM_053283.2 117159 DCD 62,395  0,120;120,159;159,261;261,351;351,517

ncbi.exonsets.gz:
tx_ac   alt_ac  method  strand  exons_se_i
NM_130786.3 NC_000019.9 splign  -1  58864769,58864865;588646...
NM_130786.3 NC_018930.2 splign  -1  58858699,58858795;588585...
NM_130786.3 AC_000151.1 splign  -1  55173924,55174020;551738...
NM_138933.2 NC_000010.10    splign  -1  52645340,52645435;52...

"""


from __future__ import division, unicode_literals

import argparse
from collections import Counter
import gzip
import importlib_resources
import io
import logging
import logging.config
import re
import sys

import Bio.SeqIO
from bioutils.digests import seq_md5

from uta.formats.txinfo import TxInfo, TxInfoWriter
from uta.parsers.seqrecord import SeqRecordFacade, SeqRecordFeatureError


origin = "NCBI"


def parse_args(argv):
    ap = argparse.ArgumentParser(
        description=__doc__,
    )
    ap.add_argument("GBFF_FILES",
                    nargs="+")
    ap.add_argument("--origin", "-o",
                    default=origin)
    ap.add_argument("--prefix", "-p",
                    default="ncbi-gbff")
    opts = ap.parse_args(argv)
    return opts


def gbff_filter(it):
    """pre-filter genbank file stream for records that match a specific LOCUS pattern"""
    delim = "//"
    emit = False
    locus_re = re.compile(r'LOCUS\s+N[MR]')
    for line in it:
        if line.startswith("LOCUS") and locus_re.match(line):
            emit = True
        if emit:
            yield line
            if line.startswith(delim):
                emit = False


def gbff_block_reader(it):
    """yield strings, each representing a full genbank record"""
    delim = "//"
    emit = None
    locus_re = re.compile(r'LOCUS\s+N[MR]')
    for line in it:
        if line.startswith("LOCUS") and locus_re.match(line):
            emit = ''
        if emit is None:
            continue
        emit += line
        if line.startswith(delim):
            yield SeqRecordFacade(Bio.SeqIO.read(io.StringIO(emit), "gb"))
            emit = None


if __name__ == "__main__":
    logging_conf_fn = importlib_resources.files("uta").joinpath("etc/logging.conf")
    logging.config.fileConfig(logging_conf_fn)
    logging.getLogger().setLevel(logging.INFO)
    logger = logging.getLogger(__name__)

    opts = parse_args(sys.argv[1:])

    tiw = TxInfoWriter(sys.stdout)

    total_genes = set()
    skipped_ids = set()
    all_prefixes = Counter()
    for fn in opts.GBFF_FILES:
        flo = gzip.open(fn, "rt")
        logger.info("opened " + fn)
        genes = set()
        prefixes = Counter()
        for srf in (SeqRecordFacade(r) for r in Bio.SeqIO.parse(flo, "gb")):
            prefixes.update([srf.id[:2]])
            if srf.id.partition("_")[0] not in ["NM", "NR"]:
                skipped_ids.add(srf.id)
                continue
            ti = TxInfo(
                ac=srf.id,
                origin=opts.origin,
                gene_id=srf.gene_id,
                gene_symbol=srf.gene_symbol,
                cds_se_i=TxInfo.serialize_cds_se_i(srf.cds_se_i),
                exons_se_i=TxInfo.serialize_exons_se_i(srf.exons_se_i),
                codon_table=srf.codon_table,
                transl_except=TxInfo.serialize_transl_except(srf.transl_except),
            )
            tiw.write(ti)
            genes.add(srf.gene_symbol)
        logger.info("{ng} genes in {fn} ({c})".format(ng=len(genes), fn=fn, c=prefixes))
        total_genes ^= genes
        all_prefixes += prefixes
    logger.info("{ng} genes in {nf} files ({c})".format(
        ng=len(total_genes), nf=len(opts.GBFF_FILES), c=all_prefixes))
