#!/usr/bin/env python

"""Write exonsets and txinfo files from NCBI GFF alignments, as obtained from
ftp://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/alignments/
This service appeared in April 2015 and is due to update weekly.

See uta.formats for a description of those file formats.

In a nutshell, this means that you'll get data like this:

ncbi.txinfo.gz:
origin  ac  hgnc    cds_se_i    exons_se_i
NCBI RefSeq NM_053283.2 DCD 62,395  0,120;120,159;159,261;261,351;351,517

ncbi.exonsets.gz:
tx_ac   alt_ac  method  strand  exons_se_i
NM_130786.3 NC_000019.9 splign  -1  58864769,58864865;588646...
NM_130786.3 NC_018930.2 splign  -1  58858699,58858795;588585...
NM_130786.3 AC_000151.1 splign  -1  55173924,55174020;551738...
NM_138933.2 NC_000010.10    splign  -1  52645340,52645435;52...

"""


from __future__ import division

import argparse
import gzip
import io
import itertools
import logging, logging.config
import os
import pprint
import pkg_resources
import re
import sys

import Bio.SeqIO
from bioutils.digests import seq_md5
import eutils.clientx

from uta.formats.exonset import ExonSet,ExonSetWriter
from uta.formats.txinfo import TxInfo,TxInfoWriter

transcript_origin='NCBI RefSeq'

def parse_args(argv):
    ap = argparse.ArgumentParser(
        description = __doc__,
        )
    ap.add_argument('in_fn')
    ap.add_argument('--prefix','-p',
                    default='ncbi-gff')
    opts = ap.parse_args(argv)
    return opts


def read_transcript_data(fn):
    """yield dictionaries of transcript alignment data; each yield
    corresponds to one full transcript record across lines"""
    
    def _read_exons(fn):
        line_re = re.compile('(?P<ref_ac>\S+)\t(?P<origin>\S+)\t(?P<match_type>\S+)\t(?P<g_start>\d+)\t(?P<g_end>\d+)\t(?P<score>\S+)\t(?P<strand>[-+])\t\.\tID=(?P<aln>aln\d+);Target=(?P<tx_ac>\S+)\s+(?P<tx_start>\d+)\s+(?P<tx_end>\d+)')
        fh = io.open(fn,'rb')
        while fh.peek(1)[0] == '#':
            fh.readline()
        while fh.peek(3)[0:3] != '###':
            line = fh.readline()
            try:
                yield line_re.match(line).groupdict()
            except AttributeError:
                raise Exception("Failed at", line)
        raise StopIteration

    return itertools.groupby(_read_exons(fn), key=lambda e: e['aln'])

def convert_exon_data(opts,eri):
    """return (TxInfo,ExonSet) tuple for given exon record data"""
    exon_recs = list(eri)
    er0 = exon_recs[0]
    ti = TxInfo(ac=er0['tx_ac'],
                origin=opts.prefix,
                hgnc=None,
                cds_se_i=",".join([str(c) for c in [None,None]]),
                exons_se_i= ";".join(["{},{}".format(int(ex['tx_start'])-1,ex['tx_end']) for ex in exon_recs])
                )
    es = ExonSet(
        tx_ac=er0['tx_ac'],
        alt_ac=er0['ref_ac'],
        method=opts.prefix,
        strand=-1 if er0['strand'] == '-' else 1,
        exons_se_i= ";".join(["{},{}".format(int(ex['g_start'])-1,ex['g_end']) for ex in exon_recs])
        )
    return (ti,es)


if __name__ == '__main__':
    logging_conf_fn = pkg_resources.resource_filename('uta', 'etc/logging.conf')
    logging.config.fileConfig(logging_conf_fn)
    logging.getLogger().setLevel(logging.INFO)
    logger = logging.getLogger(__name__)

    opts = parse_args(sys.argv[1:])

    es_fn = opts.prefix + '.exonset.gz'
    ti_fn = opts.prefix + '.txinfo.gz'

    esw = ExonSetWriter(gzip.open(es_fn+'.tmp','w'))
    tiw = TxInfoWriter(gzip.open(ti_fn+'.tmp','w'))

    for aln,eri in read_transcript_data(opts.in_fn):
        ti,es = convert_exon_data(opts,eri)
        tiw.write(ti)
        esw.write(es)

    for fn in [ti_fn,es_fn]:
        os.rename(fn+'.tmp',fn)
